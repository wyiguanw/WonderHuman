<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description"
        content="WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction">
  <meta name="keywords" content="SurgicalGaussian, 3D Reconstruction, 3D Gaussian">
  <title>WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <link rel="stylesheet" href="./static/css/ppage.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Zilong Wang<sup>1</sup>,
            </span>
            <span class="author-block">
              Zhiyang Dou<sup>2</sup>,
            </span>
            <span class="author-block">
              Yuan Liu<sup>2</sup>,
            </span>
            <span class="author-block">
              Cheng Lin<sup>2</sup>,
            </span>
            <span class="author-block">
              Xiao Dong<sup>3</sup>,
            </span>
            <span class="author-block">
              Yunhui Guo<sup>1</sup>,
            </span>
            <span class="author-block">
              Chenxu Zhang<sup>1</sup>
            <span>
            <span class="author-block">
              Xin Li<sup>4</sup>
            <span>
            <span class="author-block">
              Wenping Wang<sup>4</sup>
            <span>
            <span class="author-block">
              Xiaohu Guo<sup>1</sup>
            <span>
          </div>
              
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Texas at Dallas, 
            <sup>2</sup>The University of Hong Kong, 
            <sup>3</sup>BNU-HKBU United International College,
            <sup>3</sup>Texas A&M University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://wyiguanw.github.io/WonderHuman/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://wyiguanw.github.io/WonderHuman/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/7W1hLJBm4as"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://wyiguanw.github.io/WonderHuman/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>





<div class="container">
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Pipline4.2.png" alt="method" height="100%">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf"> Pipline of our WonderHuman
      </h2>
    </div>
  </div>
 </div>
</section>

             
              
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present WonderHuman to reconstruct dynamic human avatars from a monocular video for high-fidelity
            novel view synthesis. Previous dynamic human avatar reconstruction methods typically require the input video to have full coverage
            of the observed human body. However, in daily practice, one typically has access to limited viewpoints, such as monocular front-view
            videos, making it a cumbersome task for previous methods to reconstruct the unseen parts of the human avatar. To tackle the issue, we
            present WonderHuman, which leverages 2D generative diffusion model priors to achieve high-quality, photorealistic reconstructions of
            dynamic human avatars from monocular videos, including accurate rendering of unseen body parts. Our approach introduces a Dual-
            Space Optimization technique, applying Score Distillation Sampling (SDS) in both canonical and observation spaces to ensure visual
            consistency and enhance realism in dynamic human reconstruction. Additionally, we present a View Selection strategy and Pose Feature
            Injection to enforce the consistency between SDS predictions and observed data, ensuring pose-dependent effects and higher fidelity
            in the reconstructed avatar. In the experiments, our method achieves SOTA performance in producing photorealistic renderings from the
            given monocular video, particularly for those challenging unseen parts.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- 视频滚动 -->
<!-- <section class="section">
  <div class="container is-max-desktop">
  
 
   <br>
   <div id="video-container" style="height: 640px;">
     <video id="video-player" autoplay muted playsinline controls>
       <source src="./static/video/WonderHuman.mp4" type="video/mp4">
       Your browser does not support the video tag.
     </video> -->
     <!-- <button id="prev"></button>
     <button id="next"></button> -->
   <!-- </div> -->
   <!-- <div id="dots-container"></div> -->
   <!-- <br>
   </div>
 
 <script src="./static/js/intro.js"></script>
 </section> -->
 <!-- 视频滚动 --> 

 <section class="section">
  <div class="container is-max-desktop">
    <br>
    <div id="video-container" style="text-align: center;">
      <iframe width="640" height="360" src="https://www.youtube.com/watch?v=7W1hLJBm4as" frameborder="0" allowfullscreen></iframe>
    </div>
    <br>
  </div>
</section>

<!-- 视频滚动 -->
<section class="section">
 <div class="container is-max-desktop">
 <h3 class="title is-4">Comparison with Video-based Methods</h3>
        <div class="content has-text-justified">
          <p>
           Comparison with HumanNeRF, Instant_NVR and GaussianAvatar:
          </p>
        </div>
  <div class="articlecontrainer">
  <br>
  <div id="video-container" style="height: 600px; width: 100%">
    <video id="video-player-2" autoplay muted playsinline controls>
      <source src=" " type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <button id="prev-button-2"></button>
    <button id="next-button-2"></button>
  </div>
  <div id="dots-container-2"></div>
  <br>
  </div>
<script src="./static/js/compare_1.js"></script>
 </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
         <div class="content has-text-justified">
           <p>
            Comparison with GuessTheUnseen:
           </p>
         </div>
   <div class="articlecontrainer">
   <br>
   <div id="video-container" style="height: 600px; width: 100%">
     <video id="video-player-3" autoplay muted playsinline controls>
       <source src=" " type="video/mp4">
       Your browser does not support the video tag.
     </video>
     <button id="prev-button-3"></button>
     <button id="next-button-3"></button>
   </div>
   <div id="dots-container-3"></div>
   <br>
   </div>
 <script src="./static/js/compare_2.js"></script>
  </div>
 </section>

 <section class="section">
  <div class="container is-max-desktop">
    <h3 class="title is-4">Comparison with Image-based Methods</h3>
         <div class="content has-text-justified">
           <p>
            Comparison with SIFU, SITH, and ELICIT:
           </p>
         </div>
   <div class="articlecontrainer">
   <br>
   <div id="video-container" style="height: 600px; width: 100%">
     <video id="video-player-4" autoplay muted playsinline controls>
       <source src=" " type="video/mp4">
       Your browser does not support the video tag.
     </video>
     <button id="prev-button-4"></button>
     <button id="next-button-4"></button>
   </div>
   <div id="dots-container-4"></div>
   <br>
   </div>
 <script src="./static/js/compare_3.js"></script>
  </div>
 </section>

 <section class="section">
  <div class="container is-max-desktop">
    <h3 class="title is-4">Novel pose animations</h3>
        
   <div class="articlecontrainer">
   <br>
   <div id="video-container" style="height: 600px; width: 100%">
     <video id="video-player-5" autoplay muted playsinline controls>
       <source src=" " type="video/mp4">
       Your browser does not support the video tag.
     </video>
     <button id="prev-button-5"></button>
     <button id="next-button-5"></button>
   </div>
   <div id="dots-container-5"></div>
   <br>
   </div>
 <script src="./static/js/animation.js"></script>
  </div>
 </section>



<section class="section">
  <div class="container is-max-desktop">

    
    
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            <a href="https://github.com/aipixel/GaussianAvatar">GaussianAvatar</a>: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians
          <p>
            <a href="https://github.com/cvlab-columbia/zero123">Zero-1-to-3</a>: Zero-shot One Image to 3D Object
          <p>
          <p>
            <a href="https://github.com/YuliangXiu/ECON">ECON</a>: Explicit Clothed humans Optimized via Normal integration
          <p>
          <p>
            <a href="https://github.com/facebookresearch/sapiens">Sapiens</a>: Foundation for Human Vision Models
          <p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
              
  </div>
</section>
              

              
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>If you find this work helpful, you can cite our paper as follows:</p>
    <pre><code>
</code></pre>
  </div>
</section>
              
<section class="section" id="Contact">
  <hr>
  <div class="container is-max-desktop content">
    <p>If you have any questions or feedbacks, please contact Weixing Xie (<a href="mailto:xwxxmu@gmail.com">xwxxmu@gmail.com</a>).</p>
  </div>
</section>
              
<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website is partially borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
              


</body>
</html>
